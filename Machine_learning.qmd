---
title: "ML"
format: html
---

## Les packages

```{r,results='hide',message=FALSE}
library(ggplot2)
library(tidyverse)
library(dplyr)
library(car)
library(lubridate)

# install.packages("caret")
library(caret)
library(plotly)
library(naniar)
library(pROC)
library(ggpubr)
library(tseries)
library(GGally)
library(pander)
library(shiny)
# install.packages("shinydashboard")
library(shinydashboard)
# install.packages("randomForest")
library(randomForest)
library(DT)
library(lubridate)
library(e1071)
# install.packages("anomalize")
library(anomalize)
library(skimr)
library(isotree)
library(dbscan)
```

# Data

```{r}
# library(readr)
library(data.table)
# data.table::
data <- fread("C:/TER2/TERII/Data.csv")

train <- fread("C:/TER2/TERII/Train_set1.csv")

test <- fread("C:/TER2/TERII/Test_set1.csv") 
```

```{r}
sapply(data,class)
```

#### Qlq fonction

```{r}
df_metr <- function(pred,actual,pred_prob,noms){
  conf <- confusionMatrix(factor(pred),factor(actual))
  roc <- roc(actual,pred_prob)

  return(
  t( c(conf$byClass[c("Sensitivity","F1","Specificity","Recall","Precision")]
,conf$overall[c("Accuracy","Kappa")])) %>% cbind(AUC=roc$auc) %>% as.data.frame(row.names = noms))
}


```

# ROSE AMÉLIORÉ 

```{r}
copie <- data %>% select(-lof_amount) %>% 
  # mutate(across(where(is.character), as.factor)) %>%
  mutate(TransactionDate = as.numeric(difftime(TransactionDate, min(TransactionDate), units = "days")),
         mutate(across(c(IsFraud,IsOutlier,Weekend,night,TotalFraudMerc,score,CategorieAmount,GeoSuspicious,RapidBehaviorChange,Location),as.factor)))
# Suppression des variables inutiles et transformation de la variable cible
copie <- copie %>% select(-c(TimeSinceLastTrans_days, TimeSinceLastTrans_week))
copie$IsFraud <- ifelse(copie$IsFraud == 1, "Oui", "Non") %>% factor()


# Séparation train/test avec stratification
set.seed(1234)
index1 <- createDataPartition(copie$IsFraud, p = 0.8, list = FALSE)
train_rose <- copie[index1, ]
test_rose <- copie[-index1, ]
# Vérification de la distribution initiale
# table(train_rose$IsFraud)

# Définition du nombre d'échantillons pour l'équilibrage
n_samples <- max(table(train_rose$IsFraud)) * 2  

# Application de différentes méthodes d'équilibrage
data_balanced <- ROSE(IsFraud ~ ., data = train_rose, seed = 1234, N = n_samples)$data
data_balanced_under <- ROSE::ovun.sample(IsFraud ~ ., data = train_rose, p = 0.5, method = "under", seed = 1234)$data
data_balanced_over <- ROSE::ovun.sample(IsFraud ~ ., data = train_rose, p = 0.5, method = "over", seed = 1234)$data
data_balanced_both <- ROSE::ovun.sample(IsFraud ~ ., data = train_rose, p = 0.5, method = "both", seed = 1234)$data
data_balanced_rose <- ROSE::ROSE(IsFraud ~ ., data = train_rose, seed = 1234)$data

# Conversion en facteur pour `caret`
for (df in list(data_balanced, data_balanced_under, data_balanced_over, data_balanced_both, data_balanced_rose)) {
  df$IsFraud <- factor(df$IsFraud, levels = c("Oui", "Non"))
}

# Vérification de l'équilibrage final
list_balanced <- list(data_balanced, data_balanced_under, data_balanced_over, data_balanced_both, data_balanced_rose)
names(list_balanced) <- c("ROSE", "Under", "Over", "Both", "ROSE_Pure")

for (name in names(list_balanced)) {
  cat("\nDistribution des classes pour", name, ":\n")
  print(table(list_balanced[[name]]$IsFraud))
}

```

# ROSE2

```{r}
library(ROSE)
# Transformation des colonnes
copie <- data %>% select(-lof_amount) %>% 
  # mutate(across(where(is.character), as.factor)) %>%
  mutate(TransactionDate = as.numeric(difftime(TransactionDate, min(TransactionDate), units = "days")),
         mutate(across(c(IsFraud,IsOutlier,Weekend,night,TotalFraudMerc,score,CategorieAmount,GeoSuspicious,RapidBehaviorChange,Location),as.factor)))

copie <- copie %>% select(-c(TimeSinceLastTrans_days,TimeSinceLastTrans_week))
copie$IsFraud <- ifelse(copie$IsFraud==1,"Oui","Non")

# copie$IsFraud <- copie$IsFraud %>% factor()
# Division des données en train et test
set.seed(1234)  # Ajout d'une graine pour la reproductibilité
index1 <- createDataPartition(copie$IsFraud, p = 0.8, list = FALSE)
train_rose <- copie[index1, ]
test_rose <- copie[-index1, ]

# Appliquer ROSE pour équilibrer les classes dans l'ensemble d'entraînement
data_balanced <- ROSE(IsFraud ~ ., data = train_rose, seed = 1234,N=nrow(train_rose))$data

# Afficher la répartition des classes dans l'entraînement équilibré
table(data_balanced$IsFraud)



# Application de ROSE avec une combinaison d'over-sampling et under-sampling

data_balenced_under <- ROSE::ovun.sample(IsFraud ~ ., data = train_rose, p = 0.1,  method="under",seed=1234)$data

data_balenced_both <- ROSE::ovun.sample(IsFraud ~ ., data = train_rose, p = 0.5,  method="both",seed=1234)$data

data_balenced_over <- ROSE::ovun.sample(IsFraud ~ ., data = train_rose, p=0.3, method="over",seed=1234)$data


data_balenced_rose <- ROSE::ROSE(IsFraud ~ ., data = train_rose, seed=1234)$data

table(data_balenced_rose$IsFraud)

par(mfrow=c(2,2),new=F,bg="pink",bty="c")
col <- rainbow(2)
barplot(table(data$IsFraud),col=col,main="Données de base")
barplot(table(data_balenced_rose$IsFraud),col=col,main="Données avec Rose")
barplot(table(data_balenced_over$IsFraud),col=col,main="Données avec rose")
barplot(table(data_balenced_both$IsFraud),col=col,main="Données avec ROSE & UnderSampling")
barplot(table(data_balenced_under$IsFraud),col=col,main="Données avec UnderSamplind")
grid()

```

```{r}

# Sélectionner les variables numériques et normaliser
data_balanced_numeric <- select_if(data_balenced_over, is.numeric)
data_balanced_scaled <- scale(data_balanced_numeric)

# PCA sur les données équilibrées
pca_model_bal <- prcomp(data_balanced_scaled, center = TRUE, scale. = TRUE)

# Visualisation
pca_bal_data <- as.data.frame(pca_model_bal$x)
pca_bal_data$ISFRAUD <- as.factor(data_balenced_over$IsFraud)

ggplot(pca_bal_data, aes(x = PC3, y = PC2, color = ISFRAUD)) +
  geom_point(alpha = 0.5) +
  labs(title = "PCA après SMOTE",
       x = "Première composante",
       y = "Deuxième composante") +
  theme_minimal()


summary(pca_bal_data)
plot(pca_bal_data)
library(factoextra)
# install.packages("factoextra")
# FactoMineR::plot.PCA(pca_model_bal)
factoextra::fviz_eig(pca_model_bal,addlabels = T)

```

```{r}
# install.packages("Rtsne")
library(Rtsne)
# data_balanced_numeric <- select_if(train_rose, is.numeric)
# data_scaled <- scale(data_balanced_numeric)
# # Réduction de dimension avec t-SNE
# tsne_model <- Rtsne(data_scaled %>% na.omit(), perplexity = 30)
# 
# # Dataframe avec les résultats
# tsne_data <- as.data.frame(tsne_model$Y)
# colnames(tsne_data) <- c("Dim1", "Dim2")
# tsne_data$ISFRAUD <- as.factor(data$I)
# 
# # Visualisation
# ggplot(tsne_data, aes(x = Dim1, y = Dim2, color = ISFRAUD)) +
#   geom_point(alpha = 0.5) +
#   labs(title = "t-SNE des Transactions Bancaires",
#        x = "Dimension 1",
#        y = "Dimension 2") +
#   theme_minimal()

```

## Modele Sans Échantillonnage

#### 1-Logistique

```{r}
train_control <- trainControl(
  method = "cv",              # Validation croisée
  number = 5,                 # 5 plis
  classProbs = TRUE,          # Calcul des probabilités de classe
  summaryFunction = twoClassSummary,  # Utilisation de l'AUC pour évaluer la performance
  verboseIter = TRUE, # Affichage des détails pendant l'entraînement
  sampling="up"
)



```

```{r}
grid <- expand.grid(
  alpha=seq(0,1,by=0.2),
  lambda=seq(1,0.01,length=10 ))
```

```{r}
# c <- model_glmnet1$results
# Entraîner l'arbre de décision avec la recherche de grille pour optimiser les paramètres
model_glmnet1 <- train(
  IsFraud ~ .,                # La variable cible (IsFraud) et toutes les autres variables en prédicteurs
  data = train,               # Jeu de données d'entraînement
  method = "glmnet",           # Arbre de décision
  metric = "ROC",             # Utiliser l'AUC comme métrique
  trControl = train_control ,
  family="binomial",
  tuneGrid=grid
  # tuneGrid=grid# Passer la grille de recherche
)


pred<- predict(model_glmnet1,test)

conf_glmnet1 <- confusionMatrix(pred,factor(test$IsFraud))

conf_glmnet1

pred_prob <-  predict(model_glmnet1,test,type = "prob")[,2]

# coords(roc_glmnet1,"best")
# pred <- ifelse(pred_prob > 0.01005374	,"Oui","Non")

roc_glmnet1 <- roc(test$IsFraud,pred_prob)

par(pty="s")
roc_glmnet1 %>%  plot()

Models0 <- df_metr(pred,test$IsFraud,pred_prob,"glmnet_up") %>% rbind(Models0)

# Models0 <- cbind(df_metr(pred,factor(test$IsFraud)),AUC=roc_glmnet1$auc) %>% as.data.frame(row.names = "Glmnet")
# Models0
```

#### 2-Arbre de decision

```{r}
library(ROSE)
# install.packages("themis")
library(themis)
# Définir les paramètres de validation croisée
train_control <- trainControl(
  method = "cv",           # Cross-validation
  number = 10,             
  classProbs = TRUE,       # Prédictions en probabilités
  summaryFunction = twoClassSummary ,# Nécessaire pour "ROC"
  sampling="smote",
  verboseIter = TRUE, #up,rose,smote,down
  repeats = 5
) 

#grille pour paramètre 
grid <- expand.grid(cp =  seq(0.01, 1, by = 0.01) ) # Complexity Parameter

# Entraînement du modèle avec rpart
model_rpart_smote <- train(
  IsFraud ~ . ,
  train,               
  method = "rpart",           # Algorithme d'arbre de décision
  metric = "ROC",             # Optimisation de l'AUC
  trControl = train_control,  
  tuneGrid = grid
  # tuneLength=5
)

train_control$sampling <- NULL

model_rpart_rose <- train(
  IsFraud ~ . ,
  data_balanced_rose,               
  method = "rpart",           # Algorithme d'arbre de décision
  metric = "ROC",             # Optimisation de l'AUC
  trControl = train_control,  
  tuneGrid = grid
  # tuneLength=5
)

# data_balenced_rose$IsFraud %>% table()

train_control$sampling <- "up"

model_rpart_up <- train(
  IsFraud ~ . ,
  train,               
  method = "rpart",           # Algorithme d'arbre de décision
  metric = "ROC",             # Optimisation de l'AUC
  trControl = train_control,  
  tuneGrid = grid
  # tuneLength=5
)

train_control$sampling <- NULL

model_rpart_none <- train(
  IsFraud ~ . ,
  train,               
  method = "rpart",           # Algorithme d'arbre de décision
  metric = "ROC",             # Optimisation de l'AUC
  trControl = train_control,  
  tuneGrid = grid
  # tuneLength=5
)




```

```{r}
train_control <- trainControl(
  method = "LGOCV",           # Cross-validation
  number = 10,             
  classProbs = TRUE, 
  savePredictions="final",

  summaryFunction = twoClassSummary ,# Nécessaire pour "ROC"
  sampling="smote",
  verboseIter = TRUE #up,rose,smote,down
) 

#grille pour paramètre 
grid <- expand.grid(cp =  seq(0.01, 1, by = 0.01) ) # Complexity Parameter

# Entraînement du modèle avec rpart
model_rpart_smote2 <- train(
  IsFraud ~ . ,
  train,               
  method = "rpart",           # Algorithme d'arbre de décision
  metric = "ROC",             # Optimisation de l'AUC
  trControl = train_control,  
  tuneGrid = grid
  # tuneLength=5
)

train_control$sampling <- NULL

model_rpart_rose2 <- train(
  IsFraud ~ . ,
  data_balenced_rose,               
  method = "rpart",           # Algorithme d'arbre de décision
  metric = "ROC",             # Optimisation de l'AUC
  trControl = train_control,  
  tuneGrid = grid
  # tuneLength=5
)

# data_balenced_rose$IsFraud %>% table()

train_control$sampling <- "up"

model_rpart_up2 <- train(
  IsFraud ~ . ,
  train,               
  method = "rpart",           # Algorithme d'arbre de décision
  metric = "ROC",             # Optimisation de l'AUC
  trControl = train_control,  
  tuneGrid = grid
  # tuneLength=5
)


train_control$sampling <- NULL

model_rpart_none2 <- train(
  IsFraud ~ . ,
  train,               
  method = "rpart",           # Algorithme d'arbre de décision
  metric = "ROC",             # Optimisation de l'AUC
  trControl = train_control,  
  tuneGrid = grid
  # tuneLength=5
)



```

```{r}
# # Exemple de liste de modèles
# models_list <- list(
#   model_rpart_none = model_rpart_none,
#   model_rpart_up = model_rpart_up,
#   model_rpart_rose = model_rpart_rose,
#   model_rpart_smote = model_rpart_smote
# )
# 
# # Enregistrer la liste des modèles dans un fichier RData
# save(models_list, file = "models_list_cv.RData")
# 
# models_list_LGOCV <- list(
#   model_rpart_none = model_rpart_none2,
#   model_rpart_up = model_rpart_up2,
#   model_rpart_rose = model_rpart_rose2,
#   model_rpart_smote = model_rpart_smote2
# )
# 
# # Enregistrer la liste des modèles avec saveRDS
# saveRDS(models_list, file = "models_list.rds")
# (models_list, file = "models_list_LGOCV.RData")




# Séparation des variables explicatives et de la cible
y_test <- test$IsFraud
y_test_rose <- test_rose$IsFraud

x_test <- test %>% select(-IsFraud)
x_test_rose <- test_rose %>% select(-IsFraud)

# Prédictions binaires
prediction_rpart_none <- predict(model_rpart_none, x_test)
prediction_rpart_up <- predict(model_rpart_up, x_test)
prediction_rpart_smote <- predict(model_rpart_smote, x_test)
prediction_rpart_rose <- predict(model_rpart_rose, x_test_rose)

# Matrices de confusion
conf_rpart_none <- confusionMatrix(prediction_rpart_none, factor(y_test))
conf_rpart_up <- confusionMatrix(prediction_rpart_up, factor(y_test))
conf_rpart_smote <- confusionMatrix(prediction_rpart_smote, factor(y_test))
# conf_rpart_rose <- confusionMatrix(prediction_rpart_rose, factor(test_rose$IsFraud))

# Affichage des matrices de confusion
conf_rpart_none
conf_rpart_up
conf_rpart_smote
# conf_rpart_rose

# Prédictions en probabilité
pred_rpart_none <- predict(model_rpart_none, newdata = x_test, type = "prob")[,2]
pred_rpart_up <- predict(model_rpart_up, newdata = x_test, type = "prob")[,2]
pred_rpart_smote <- predict(model_rpart_smote, newdata = x_test, type = "prob")[,2]
# pred_rpart_rose <- predict(model_rpart_rose, newdata = x_test_rose, type = "prob")[,2]

# Calcul des courbes ROC
roc_rpart_none <- roc(y_test, pred_rpart_none)
roc_rpart_up <- roc(y_test, pred_rpart_up)
roc_rpart_smote <- roc(y_test, pred_rpart_smote)
# roc_rpart_rose <- roc(y_test_rose, pred_rpart_rose)

# Seuils optimaux basés sur la ROC
seuil_none <- coords(roc_rpart_none, "best", ret = "threshold", transpose = TRUE)
seuil_up <- coords(roc_rpart_up, "best", ret = "threshold", transpose = TRUE)
seuil_smote <- coords(roc_rpart_smote, "best", ret = "threshold", transpose = TRUE)
# seuil_rose <- coords(roc_rpart_rose, "best", ret = "threshold", transpose = TRUE)

# Modèle "None"
pred_none <- ifelse(pred_rpart_none > seuil_none, "Oui", "Non") %>% as.factor()
conf_rpart_none <- confusionMatrix(pred_none, factor(test$IsFraud))
auc_rpart_none <- roc(test$IsFraud, pred_rpart_none)$auc

# Modèle "Up-Sampling"
pred_up <- ifelse(pred_rpart_up > seuil_up, "Oui", "Non") %>% as.factor()
conf_rpart_up <- confusionMatrix(pred_up, factor(test$IsFraud))
auc_rpart_up <- roc(test$IsFraud, pred_rpart_up)$auc

# Modèle "SMOTE"
pred_smote <- ifelse(pred_rpart_smote > seuil_smote, "Oui", "Non") %>% as.factor()
conf_rpart_smote <- confusionMatrix(pred_smote, factor(test$IsFraud))
auc_rpart_smote <- roc(test$IsFraud, pred_rpart_smote)$auc

# Modèle "ROSE"
# pred_rose <- ifelse(pred_rpart_rose > seuil_rose, "Oui", "Non") %>% as.factor()
# conf_rpart_rose <- confusionMatrix(pred_rose, factor(test_rose$IsFraud))
# auc_rpart_rose <- roc(test_rose$IsFraud, pred_rpart_rose)$auc

# Affichage des résultats
conf_rpart_none
conf_rpart_up
conf_rpart_smote
# conf_rpart_rose

auc_rpart_none
auc_rpart_up
auc_rpart_smote
# auc_rpart_rose




# Tracer la première courbe ROC (modèle "none") en rouge
par(pty = "s")  # Garder le graphique carré pour la ROC
plot(roc_rpart_none, col = "red", lwd = 2, main = "Courbes ROC - Comparaison des modèles")

# Ajouter les autres courbes ROC avec lines()
lines(roc_rpart_up, col = "blue", lwd = 2)
lines(roc_rpart_smote, col = "green", lwd = 2)
# lines(roc_rpart_rose, col = "purple", lwd = 2)

# Ajouter une légende pour identifier chaque courbe
legend("bottomright",
       legend = c("None", "Up-Sampling", "SMOTE", "ROSE"),
       col = c("red", "blue", "green"),# "purple"),
       lwd = 2)


```

```{r}
# Prédictions binaires pour chaque modèle avec suffixe 2
prediction_rpart_none2 <- predict(model_rpart_none2, x_test)
prediction_rpart_up2 <- predict(model_rpart_up2, x_test)
prediction_rpart_smote2 <- predict(model_rpart_smote2, x_test)
# prediction_rpart_rose2 <- predict(model_rpart_rose2, x_test_rose)

# Matrices de confusion pour chaque modèle avec suffixe 2
conf_rpart_none2 <- confusionMatrix(prediction_rpart_none2, factor(y_test))
conf_rpart_up2 <- confusionMatrix(prediction_rpart_up2, factor(y_test))
conf_rpart_smote2 <- confusionMatrix(prediction_rpart_smote2, factor(y_test))
# conf_rpart_rose2 <- confusionMatrix(prediction_rpart_rose2, factor(y_test_rose))

# Prédictions en probabilité pour chaque modèle avec suffixe 2
pred_rpart_none2 <- predict(model_rpart_none2, newdata = x_test, type = "prob")[,2]
pred_rpart_up2 <- predict(model_rpart_up2, newdata = x_test, type = "prob")[,2]
pred_rpart_smote2 <- predict(model_rpart_smote2, newdata = x_test, type = "prob")[,2]
# pred_rpart_rose2 <- predict(model_rpart_rose2, newdata = x_test_rose, type = "prob")[,2]

# Calcul des courbes ROC pour chaque modèle avec suffixe 2
roc_rpart_none2 <- roc(y_test, pred_rpart_none2)
roc_rpart_up2 <- roc(y_test, pred_rpart_up2)
roc_rpart_smote2 <- roc(y_test, pred_rpart_smote2)
# roc_rpart_rose2 <- roc(y_test_rose, pred_rpart_rose2)

# Seuils optimaux pour chaque modèle avec suffixe 2
seuil_none2 <- coords(roc_rpart_none2, "best", ret = "threshold", transpose = TRUE)
seuil_up2 <- coords(roc_rpart_up2, "best", ret = "threshold", transpose = TRUE)
seuil_smote2 <- coords(roc_rpart_smote2, "best", ret = "threshold", transpose = TRUE)
# seuil_rose2 <- coords(roc_rpart_rose2, "best", ret = "threshold", transpose = TRUE)

# Prédictions binaires pour chaque modèle avec suffixe 2 en utilisant les seuils optimaux
pred_none2 <- ifelse(pred_rpart_none2 > seuil_none2, "Oui", "Non") %>% as.factor()
pred_up2 <- ifelse(pred_rpart_up2 > seuil_up2, "Oui", "Non") %>% as.factor()
pred_smote2 <- ifelse(pred_rpart_smote2 > seuil_smote2, "Oui", "Non") %>% as.factor()
# pred_rose2 <- ifelse(pred_rpart_rose2 > seuil_rose2, "Oui", "Non") %>% as.factor()

# Matrices de confusion pour les prédictions binaires
conf_rpart_none2 <- confusionMatrix(pred_none2, factor(test$IsFraud))
conf_rpart_up2 <- confusionMatrix(pred_up2, factor(test$IsFraud))
conf_rpart_smote2 <- confusionMatrix(pred_smote2, factor(test$IsFraud))
# conf_rpart_rose2 <- confusionMatrix(pred_rose2, factor(test_rose$IsFraud))

# AUC pour chaque modèle avec suffixe 2
auc_rpart_none2 <- roc(test$IsFraud, pred_rpart_none2)$auc
auc_rpart_up2 <- roc(test$IsFraud, pred_rpart_up2)$auc
auc_rpart_smote2 <- roc(test$IsFraud, pred_rpart_smote2)$auc
# auc_rpart_rose2 <- roc(test_rose$IsFraud, pred_rpart_rose2)$auc

# Affichage des matrices de confusion
conf_rpart_none2
conf_rpart_up2
conf_rpart_smote2
# conf_rpart_rose2

# Affichage des AUC
auc_rpart_none2
auc_rpart_up2
auc_rpart_smote2
# auc_rpart_rose2

# Tracer les courbes ROC pour tous les modèles avec suffixe 2
par(pty = "s")  # Garder le graphique carré pour la ROC
plot(roc_rpart_none2, col = "orange", lwd = 2, main = "Courbes ROC - Modèles avec suffixe 2")

# Ajouter les autres courbes ROC avec lines()
lines(roc_rpart_up2, col = "brown", lwd = 2)
lines(roc_rpart_smote2, col = "pink", lwd = 2)
# lines(roc_rpart_rose2, col = "cyan", lwd = 2)

# Ajouter une légende pour identifier chaque courbe
legend("bottomright",
       legend = 
             c("None2", "Up-Sampling2", "SMOTE2"),# "ROSE2"),
               # "None", "Up-Sampling", "SMOTE", "ROSE"),
        col = c("orange", "brown", "pink"),# "cyan"),
                # "red", "blue", "green", "purple"),
       lwd = 2)

```

#### RandomForest

```{r}
# install.packages("ranger")t 
library(ranger)
library(caret)

# Définir la grille d'hyperparamètres
tune_grid <- expand.grid(
  mtry = c(3, 5, 7),                # Nombre de variables à considérer pour chaque split
  splitrule = "gini",               # Critère de division
  min.node.size = c(1, 5, 10)       # Taille minimale des nœuds
)

# Configurer le contrôle de l'entraînement
train_control <- trainControl(
  method = "cv",                    # Validation croisée
  number = 5,                       # Nombre de folds
  classProbs = TRUE,                # Prédire les probabilités
  summaryFunction = twoClassSummary # Métrique pour les classes déséquilibrées
)

# Entraîner le modèle avec caret
rf_model <- train(
  x = train[, -which(names(train) == "IsFraud")],  # Variables explicatives
  y = train$IsFraud %>% factor(),                  # Variable cible
  method = "ranger",                              # Utiliser ranger
  trControl = train_control,                      # Contrôle de l'entraînement
  tuneGrid = tune_grid,                           # Grille d'hyperparamètres
  metric = "ROC",                                 # Optimiser pour l'AUC
  class.weights = c("0" = 0.01, "1" = 0.99)       # Poids des classes
)

# Afficher les meilleurs hyperparamètres
print(rf_model$bestTune)



# model_rf1 <- train(
#   IsFraud ~ .,                # La variable cible (IsFraud) et toutes les autres variables en prédicteurs
#   data = train,               # Jeu de données d'entraînement
#   method = "rf",           # Arbre de décision
#   metric = "ROC",             # Utiliser l'AUC comme métrique
#   trControl = train_control ,
#   tuneGrid=grid,
#   tuneLenght=5,
#   weights=ifelse(train$IsFraud=="Oui",sum(train$IsFraud=="Non")/sum(train$IsFraud=="Oui"),1)
#   # tuneGrid=grid# Passer la grille de recherche
# )

library(ranger)
library(caret)
library(DMwR)  # Pour SMOTE si nécessaire
library(pROC)  # Pour les courbes ROC

# Définir une grille d'hyperparamètres plus large
tune_grid <- expand.grid(
  mtry = c(2, 5, 7, 10, 12, 15),               # Plus de valeurs pour mtry
  splitrule = "gini",                          # Critère de division basé sur Gini
  min.node.size = c(1, 3, 5, 10, 15)           # Plus de tailles de nœuds
)

# Configurer le contrôle d'entraînement avec un rééchantillonnage SMOTE et validation croisée
train_control <- trainControl(
  method = "repeatedcv",                              # Validation croisée (cross-validation)
  number = 10,   
  repeats=5,
  classProbs = TRUE,                          # Calcul des probabilités pour chaque classe
  summaryFunction = twoClassSummary,          # Fonction pour évaluer AUC et autres métriques pour classes déséquilibrées
  sampling = "smote",                         # Utilisation de SMOTE pour équilibrer les classes
  verboseIter = TRUE,                         # Affichage des progrès de l'entraînement
  search = "grid",                            # Recherche exhaustive dans la grille d'hyperparamètres
  savePredictions = "final"                   # Sauvegarder les prédictions finales pour chaque modèle
)

# Entraîner le modèle avec caret et ranger
rf_model <- train(
  x = train[, -which(names(train) == "IsFraud")],    # Variables explicatives sans la variable cible "IsFraud"
  y = train$IsFraud %>% factor(),                    # Variable cible "IsFraud" transformée en facteur
  method = "ranger",                                 # Utilisation du modèle Ranger (Random Forest)
  trControl = train_control,                         # Contrôle de l'entraînement
  tuneGrid = tune_grid,                              # Hyperparamètres à tester dans la grille
  metric = "ROC",                                    # Critère d'optimisation (AUC - courbe ROC)
  class.weights = NULL                               # Pas de poids explicites (SMOTE gère cela)
)

# Affichage des meilleurs hyperparamètres
print("Meilleurs hyperparamètres trouvés :")
print(rf_model$bestTune)

# Affichage de la performance du modèle
print("Matrice de confusion finale :")
conf_ranger <- confusionMatrix(rf_model)
print(conf_ranger)

# AUC (Aire sous la courbe ROC) du modèle final
roc_curve <- roc(train$IsFraud, rf_model$pred$Yes)
auc_score <- auc(roc_curve)
print(paste("AUC: ", auc_score))

# Tracer la courbe ROC du modèle final
plot(roc_curve, col = "blue", main = "Courbe ROC - Modèle Ranger Optimisé")


```

#### 4-SVM

```{r}
grid <- expand.grid(C = c(0.1, 1, 10), sigma = c(0.01, 0.1, 1))


model_svm <- train(
  IsFraud ~ .,                
  data = train,               
  method = "svmRadial",  # SVM à noyau radial        
  metric = "ROC",             
  trControl = train_control,
  tuneLength = 5 , # OU utiliser tuneGrid=grid si tu veux définir manuellement
  tuneGrid=grid
)
 library(e1071)
set.seed(123)

# Définition des poids pour gérer le déséquilibre des classes
class_weights <- c("Non" = 1, "Oui" = sum(train$IsFraud == "Non") / sum(train$IsFraud == "Oui"))

# Recherche des meilleurs paramètres
tuned_svm <- tune.svm(
  IsFraud ~ ., 
  data = Train, 
  kernel = "radial", 
  cost = 10^seq(-2, 2, 1),   # Essai de plusieurs valeurs de C
  gamma = 10^seq(-3, 1, 1),  # Essai de plusieurs valeurs de gamma
  class.weights = class_weights
)

# Meilleur modèle
best_model <- tuned_svm$best.model
summary(best_model)

 # different parametre de svm
#  svm(IsFraud~. , data=Train, scale = TRUE, type = NULL, kernel =
# "radial", degree = 3, gamma = if (is.vector(x)) 1 else 1 / ncol(x),
# coef0 = 0, cost = 1, nu = 0.5,
# class.weights = NULL, cachesize = 40, tolerance = 0.001, epsilon = 0.1,
# shrinking = TRUE, cross = 0, probability = FALSE, fitted = TRUE,)

```

Ksvm                  

```{r}
library(caret)
library(kernlab)
set.seed(123)

# Calcul des poids de classe
class_weights <- c("Non" = 1, "Oui" = sum(train$IsFraud == "Non") / sum(train$IsFraud == "Oui"))

model_svm <- ksvm(
  IsFraud ~ .,                
  data = Train,               
  kernel = "rbfdot",  # Noyau radial
  prob.model = TRUE,  # Pour les probabilités
  class.weights = class_weights  # Ajout des poids pour compenser le déséquilibre
)

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

#### 5-LightGbm

```{r}
library(lightgbm)
Y_train <- as.numeric(train$IsFraud=="Oui")
Y_test <- as.numeric(test$IsFraud=="Oui")

# Calculer les poids pour compenser le déséquilibre des classes
weights_train <- ifelse(train$IsFraud == "Oui", sum(train$IsFraud == "Non") / sum(train$IsFraud == "Oui"), 1)

# Créer les objets lgb.Dataset pour LightGBM
lgb_train <- lgb.Dataset(data = as.matrix(train %>% select(-IsFraud)), label = Y_train, weight = weights_train)
lgb_test <- lgb.Dataset(data = as.matrix(test %>% select(-IsFraud)), label = Y_test)

```

```{r}
parames <- list(
  objective="binary",
  bagging_fraction=0.8,
  metric="auc",
  max_depth=30,
  # scale_pos_weight= weight,<
  learning_rate=0.01,
  lambda_l1=0.1,
  lambda_l2=1,
  num_leaves=30,
  # bagging_fraction=0.7
  bagging_freq=5,
  min_data_in_leaf=200,
   # boosting_type="gbdt",
  feature_fraction=0.7
)
# rid_params <- expand.grid(
#   learning_rate = c(0.01, 0.05, 0.1),
#   num_leaves = c(31, 100),
#   max_depth = c(-1, 10, 20),
#   bagging_fraction = c(0.7, 0.8),
#   feature_fraction = c(0.7, 0.8),
#   lambda_l1 = c(0.1, 0.5, 1.0),
#   lambda_l2 = c(0.1, 0.5, 1.0)
# )

model_lgb <- lgb.train(
  params = parames,
  data=lgb_train,
  # label=train_label,
  nrounds = 300,
  valids = list(test=lgb_test),
  early_stopping_rounds = 100,
  verbose = 1
)
liste_lgm <- model_lgb$params %>% t %>% as.list() %>% cbind(model_lgb$best_score) %>% rbind(liste_lgm)

pred_prob <- predict(model_lgb,as.matrix(test %>% select(-IsFraud)))


# Prédiction des probabilités sur le jeu de test
# pred_prob <- predict(model_lgb_rose, mat_test_rose)

# Calcul de la courbe ROC
roc_lgb <- roc(Y_test, pred_prob)

# Visualiser la courbe ROC
plot(roc_lgb, main = "Courbe ROC - LightGBM")

# Trouver le seuil optimal pour maximiser une métrique (ici : spécificité)
seuil <- coords(roc_lgb, "best", ret = "threshold", transpose = TRUE)
# coords(roc_lgb,"best")

# Transformer les probabilités en classes avec le seuil optimal
pred_value <- ifelse(pred_prob > seuil, "Oui","Non")

# Générer une matrice de confusion
conf_lgb <- confusionMatrix(factor(pred_value), factor(test$IsFraud))
# conf_matrix$byClass

conf_lgb

model_lgb$record_evals

# 
# Models0 <- df_metr(factor(pred_value), factor(test$IsFraud),pred_prob,"lgbm1") %>% rbind(Models0)
```

```{r}
# 
# Models0 <- cbind(df_metr(factor(pred_value), factor(test$IsFraud)),AUC=roc_lgb$auc) %>% as.data.frame(row.names = "lgb")%>% rbind(Models0) 

```

```{r}
```

```{r}
# # # Charger les bibliothèques nécessaires
# # library(lightgbm)
# # library(dplyr)
# # 
# # Définir la grille de paramètres
# grid_params <- expand.grid(
#   learning_rate = c(0.01, 0.05, 0.1),
#   num_leaves = c(31, 100),
#   max_depth = c(-1, 10, 20),
#   bagging_fraction = c(0.7, 0.8),
#   feature_fraction = c(0.7, 0.8),
#   lambda_l1 = c(0.1, 0.5, 1.0),
#   lambda_l2 = c(0.1, 0.5, 1.0)
# )
# 
# # Fonction d'entraînement avec validation croisée
# train_with_cv <- function(params, train_data, num_folds = 5, nrounds = 50, early_stopping_rounds = 10) {
#   cv_results <- lgb.cv(
#     params = as.list(params),
#     data = train_data,
#     nrounds = nrounds,
#     nfold = num_folds,
#     stratified = TRUE,
#     early_stopping_rounds = early_stopping_rounds,
#     verbose = 1
#   )
#   list(best_iteration = cv_results$best_iter, best_score = cv_results$best_score)
# }
# 
# # Entraîner et évaluer les modèles
# grid_results <- apply(grid_params, 1, function(params_row) {
#   params <- as.list(params_row)
#   params$objective <- "binary"
#   params$metric <- "binary_logloss"
#   params$bagging_freq <- 5
#   params$min_data_in_leaf <- 200
#   cv_result <- train_with_cv(params, lgb_train)
#   c(params, cv_result)
# })
# 
# # Afficher les meilleurs résultats
# sorted_results <- grid_results %>%
#   data.frame() %>%
#   arrange(desc(best_score))
# 
# print(sorted_results[1, ])

```

#### 6-Catboost

```{r}
X_train<- train %>% select(-IsFraud)
X_test <- test %>% select(-IsFraud)

Y_train <- train$IsFraud
Y_test <- test$IsFraud
library(catboost)

mat_train <- model.matrix(IsFraud~.-1,train)
mat_test <- model.matrix(IsFraud~.-1,test)


train_cat <- catboost.load_pool(mat_train,label=as.numeric(Y_train=="Oui"))
test_cat <- catboost.load_pool(mat_test,label=as.numeric(Y_test=="Oui"))
```

```{r}
# Paramètres du modèle
params <- list(
  loss_function = "Logloss",  # Fonction de perte pour la classification binaire (logarithmique)
  
  eval_metric = "AUC",  # Métrique d'évaluation (Kappa est utile pour les classes déséquilibrées)
  
  iterations = 300,  # Nombre total d'arbres à entraîner (augmenter pour de meilleures performances)
  
  learning_rate = 0.01,  # Taux d'apprentissage : plus il est faible, plus l'entraînement est stable mais lent.
  
  depth = 10,  # Profondeur maximale des arbres (6 est un bon compromis entre complexité et généralisation)
  
  task_type = "GPU",  # Mode d'entraînement : "CPU" ou "GPU" (mettre "GPU" si tu veux accélérer avec une carte graphique)
  
  l2_leaf_reg = 3,  # Régularisation L2 pour éviter le surajustement (valeur par défaut = 3, peut être ajustée)
  
  class_weights = c(1, sum(train$IsFraud == "Non") / sum(train$IsFraud == "Oui")),  
  # ⚠️ Correction de la syntaxe et explication :
  # - Utilisé pour gérer le déséquilibre des classes (fraude = "Oui" est souvent sous-représenté)
  # - La classe "Non" a un poids de 1 (référence)
  # - La classe "Oui" a un poids plus grand pour compenser le déséquilibre
  
  random_strength = 1,  # Contrôle la force du bruit aléatoire ajouté pour éviter le surajustement
  
  border_count = 254,  # Nombre de divisions utilisées pour discrétiser les variables continues (valeur élevée = plus de précision)
  
  thread_count = 4,  # Nombre de cœurs du processeur utilisés pour l'entraînement (optimiser selon ta machine)
  
  bagging_temperature = 3  # Contrôle la force du bagging (stochasticité du bootstrap) : 
  # - 0 = pur boosting déterministe
  # - 1 = boostrap normal
  # - >1 = plus de diversité entre les arbres, utile pour éviter le surajustement
)
list_cat <- model_cat$cpp_obj
# params$learning_rate <- 0.6

# Entraîner le modèle
model_cat <- catboost.train(train_cat, params = params)

# Faire des prédictions
preds <- catboost.predict(model_cat, test_cat, prediction_type = "Probability")


# Évaluation des performances
library(pROC)
roc_cat <- roc(test$IsFraud, preds)
auc <- auc(roc_cat)

s <- coords(roc_cat,"best",ret="threshold",transpose=T)
pred_prob <- ifelse(preds > 0.1626976 ,"Oui","Non") %>% as.factor()

conf_cat <- confusionMatrix(pred_prob,factor(test$IsFraud))
# Afficher les résultats
print(paste("AUC:", round(auc, 2)))

par(pty="s")
plot(roc_curve)

auc

k <- coords(roc_cat)

```

```{r}
# Models0 <- cbind(df_metr(pred_prob,factor(test$IsFraud)),AUC=roc_cat$auc) %>% as.data.frame(row.names = "CatBoost")%>% rbind(Models0) 
```

#### 7-Gradient boosting

```{r}
library(xgboost)
train_xgb <- xgb.DMatrix(mat_train,label= as.numeric(Y_train=="Oui"))
test_xgb <- xgb.DMatrix(mat_test,label=as.numeric(Y_test=="Oui"))
```

```{r}
params <- list(
  booster = "gbtree",
  eta = 0.25,
  gamma = 1,
  max_depth = 6,  # Réduire la profondeur pour éviter le sur-apprentissage
  lambda = 1,
  # scale_pos_weight = class_ratio,
  colsample_bytree = 0.7,  # Échantillonner moins de variables
  subsample = 0.75,  # Réduire le sur-apprentissage
  objective = "binary:logistic",
  eval_metric = "aucpr",
  alpha=0
)


# Entraînement du modèle XGBoost
model_xgb <- xgb.train(
  params = params,
  data = train_xgb,
  nrounds = 300,  # Augmentez ce chiffre pour un meilleur apprentissage
  early_stopping_rounds = 100,  # Arrêt anticipé si les performances stagnent
  watchlist = list(train = train_xgb,dtest=test_xgb),
  verbose = 1,
  nfold = 5,  # 5-Fold Cross Validation
  stratified = TRUE,  # Maintient la répartition des classes

)
 pred_prob <- predict(model_xgb,test_xgb)
 
 
 roc_xgb <- roc(test$IsFraud,pred_prob)
roc_xgb %>% plot()
 k <- coords(roc_xgb,"best",ret="threshold",transpose=T)
 d <- coords(roc_xgb,best.method="youden")
 
pred_aju <- ifelse(pred_prob > k, "Oui","Non") %>% factor() # 0.05085070
 # meilleur comromis trouver
 # k <- 1.330053e-05
 confusionMatrix(pred_aju,factor(test$IsFraud))


 # head(roc)
 
 # d <- roc[roc$tpp > 45 & roc$tpp < 75,]
# Afficher les performances finales
print(model_xgb)
list_xgb <- model_xgb$params %>% t %>% as.list() %>% cbind(model_xgb$best_score) %>% rbind(list_xgb)

```

```{r}
# list1 <- list_xgb
# Models0 <- cbind(df_metr(factor(pred_value), factor(test$IsFraud)),AUC=roc_xgb$auc) %>% as.data.frame(row.names = "xgb")%>% rbind(Models0) 
```

```{r}

train_control <- trainControl(
  method = "cv", 
  number = 5, 
  classProbs = TRUE,  # Activer les probabilités de classe pour la classification
  summaryFunction = twoClassSummary
)


# Étape 6 : Entraîner le modèle en utilisant XGBoost
model_xgb1 <- train(
  x = mat_train,  # Variables explicatives
  y = Y_train,  # Variable cible
  method = "xgbTree",  # Utilisation de XGBoost
  metric = "ROC",  # Utilisation de la métrique ROC pour la classification binaire
  trControl = train_control,  # Appliquer trainControl
  tuneGrid = expand.grid(
    nrounds = c(100,30,80),  # Nombre d'arbres
    max_depth = c(6,8,7,20,30) , # Profondeur maximale des arbres
    eta = c(0.1,0.001,0.05,0.03,1),  # Taux d'apprentissage
    gamma = c(0,1,0.5) , # Paramètre de régularisation
    colsample_bytree = 0.8,  # Fraction des variables pour chaque arbre
    min_child_weight = 1,  # Poids minimum des échantillons dans un nœud
    subsample = 0.8  # Fraction des données utilisées pour l'entraînement
  )
)



# Étape 7 : Réentraîner le modèle avec les meilleurs paramètres
model_xgb2 <- train(
  x = x_train,  # Variables explicatives
  y = y_train,  # Variable cible
  method = "xgbTree",  # Utilisation de XGBoost
  metric = "ROC",  # Utilisation de la métrique ROC pour la classification binaire
  trControl = train_control,  # Appliquer trainControl
  tuneGrid = param
)
```

#### Keras regression logistique

```{r}
# install.packages("keras")
library(keras)
```

```{r}
# Train <- train
# Train$Amount <- scale(Train$Amount,center = T,scale = T)
# mat_train <- model.matrix(IsFraud~.-1,Train)
```

```{r}
Y_Train <- as.numeric(Y_train=="Oui")
```

```{r}


```

```{r}
# # Convertir la variable cible en binaire (0/1)
# train$IsFraud <- ifelse(train$IsFraud == "Oui", 1, 0)
# test$IsFraud <- ifelse(test$IsFraud == "Oui", 1, 0)
# 
# # Séparer les variables explicatives et la cible
# X_train <- train %>% select(-IsFraud) %>% as.matrix()
# Y_train <- train$IsFraud
# 
# X_test <- test %>% select(-IsFraud) %>% as.matrix()
# Y_test <- test$IsFraud

```

```{r}
# # Définition du modèle
# model_keras <- keras_model_sequential() %>%
#   layer_dense(units = 64, activation = "relu", input_shape = ncol(X_train)) %>%
#   layer_dropout(rate = 0.3) %>%  # Réduction du surapprentissage
#   layer_dense(units = 32, activation = "relu") %>%
#   layer_dropout(rate = 0.3) %>%
#   layer_dense(units = 1, activation = "sigmoid")  # Sortie binaire
# 
# # Compilation du modèle
# model_keras %>% compile(
#   loss = "binary_crossentropy",
#   optimizer = optimizer_adam(lr = 0.001),
#   metrics = c("accuracy", metric_auc())  # Suivi de l'AUC
# )

```

```{r}
# history <- model_keras %>% fit(
#   X_train, Y_train,
#   epochs = 50,        # Nombre d'itérations
#   batch_size = 32,    # Taille du mini-lot
#   validation_split = 0.2,
#   verbose = 1
# )

```

#### 8-Adaboost

```{r}
library(ada)
# install.packages("adabag")
library(adabag)
# devtools::install_github("souravc83/fastAdaboost")
library(fastAdaboost)
# install.packages(fastad)
train_control <- trainControl(
  method = "cv",         # Validation croisée
  number = 5,            # Nombre de folds
  classProbs = TRUE,     # Nécessaire pour les modèles de classification
  summaryFunction = twoClassSummary,  # Utilisation de l'AUC pour la performance
  verboseIter = TRUE     # Afficher les itérations en temps réel
)

```

```{r}
model_adaboost <- train(
  IsFraud ~ .,
  data = train,
  method = "adaboost",  # Méthode AdaBoost
  trControl = train_control,
  metric = "ROC"  # Utilisation de l'AUC comme métrique principale
  # tuneGrid = expand.grid(nIter=c())
)
# # fastAdaboost::adaboost()
# boosting(IsFraud~.,train)
```

```{r}
ctrl <- trainControl(method = "cv", number=5,
                     classProbs = TRUE,
                     summaryFunction = twoClassSummary,
                     ## new option here:
                     sampling = "up",
                     verboseIter =T)

# write.csv(Models0,file="Models0")
```

```{r}
 model_nbagg <- train(IsFraud ~ ., data = train,
                     method = "treebag",
                     # nbagg = 50,
                     metric = "ROC",
                     trControl = ctrl)
```

```{r}
# Installer les packages nécessaires
# install.packages("caret")
# install.packages("randomForest")
# install.packages("xgboost")
# install.packages("lightgbm")
# install.packages("catboost")
# install.packages("ada")
# install.packages("rose")
# install.packages("pROC")  # Pour courbes ROC et AUC

library(caret)
library(randomForest)
library(xgboost)
library(lightgbm)
library(catboost)
library(ada)
library(rose)
library(pROC)


# Charger les données (par exemple, un fichier CSV)
# data <- read.csv("path_to_your_data.csv")

# Préparation des données
# data$IsFraud <- as.factor(data$IsFraud)
# data <- na.omit(data)  # Enlever les valeurs manquantes
# 
# # Séparer les données en ensemble d'entraînement et de test
# set.seed(123)
# trainIndex <- createDataPartition(data$IsFraud, p = 0.7, list = FALSE)
# train_data <- data[trainIndex, ]
# test_data <- data[-trainIndex, ]
# 
# # Utiliser le package 'rose' pour équilibrer les classes
# train_data_balanced <- ROSE(IsFraud ~ ., data = train, seed = 123)$data

# Entraînement des modèles de base

# 1. Random Forest
data_balenced_both$IsFraud %>% as.factor -> data_balenced_both$IsFraud
train_data_balanced<- data_balenced_both
rf_model <- randomForest(IsFraud ~ ., data =train_data_balanced, ntree = 100)
rf_pred <- predict(rf_model, newdata = test_rose, type = "response")
test_data <- test_rose

# 2. XGBoost
xgb_data <- data.matrix(train_data_balanced[, -which(names(train_data_balanced) == "IsFraud")])
xgb_label <- as.numeric(train_data_balanced$IsFraud) - 1
xgb_model <- xgboost(data = xgb_data, label = xgb_label, nrounds = 100, objective = "binary:logistic")
xgb_pred <- predict(xgb_model, newdata = data.matrix(test_data[, -which(names(test_data) == "IsFraud")]))

library(lightgbm)
# 3. LightGBM
lgb_data <- data.matrix(train_data_balanced[, -which(names(train_data_balanced) == "IsFraud")])
lgb_label <- as.numeric(train_data_balanced$IsFraud) - 1
lgb_model <- lightgbm(data = lgb_data, label = lgb_label, objective = "binary", nrounds = 100)
lgb_pred <- predict(lgb_model, newdata = data.matrix(test_data[, -which(names(test_data) == "IsFraud")]))

library(catboost)
# 4. CatBoost
cat_data <- train_data_balanced[, -which(names(train_data_balanced) == "IsFraud")]
cat_label <- as.numeric(train_data_balanced$IsFraud) - 1
cat_model <- catboost.train(data = cat_data, label = cat_label)
cat_pred <- catboost.predict(cat_model, test_data[, -which(names(test_data) == "IsFraud")])

# 5. AdaBoost
library(ada)
ada_model <- ada(IsFraud ~ ., data = train_data_balanced, iter = 100)
ada_pred <- predict(ada_model, newdata = test_data, type = "class")

# Création des données pour le stacking
stacking_data <- data.frame(
  rf_pred = as.numeric(rf_pred),
  xgb_pred = xgb_pred,
  lgb_pred = lgb_pred,
  cat_pred = cat_pred,
  ada_pred = as.numeric(ada_pred)
)
stacking_data$IsFraud <- test_data$IsFraud

# Entraîner un modèle de stacking (régression logistique)
meta_model <- train(IsFraud ~ ., data = stacking_data, method = "glm", family = "binomial")

# Prédictions du modèle de stacking
final_pred <- predict(meta_model, newdata = stacking_data)

# Évaluation des performances
confusion_matrix <- confusionMatrix(final_pred, stacking_data$IsFraud)
print(confusion_matrix)

# Calcul de l'AUC-ROC
roc_curve <- roc(stacking_data$IsFraud, as.numeric(final_pred))
print(auc(roc_curve))

# Afficher la courbe ROC
plot.roc(roc_curve)


```
